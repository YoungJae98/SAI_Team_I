# 두번째 과제

---

# 문제 1.

### 문제 내용)

---

```
3. 강의에서 설명했던 cost(비용함수)인 MSE(아래 식)에 대하여 **틀린** 것을 고르시오
(이때, Yi 와 Yi hat 은 scalar 이 아니라 길이가 2 이상인 vector 을 의미한다고 생각한다.)
```

![%E1%84%83%E1%85%AE%E1%84%87%E1%85%A5%E1%86%AB%E1%84%8D%E1%85%A2%20%E1%84%80%E1%85%AA%E1%84%8C%E1%85%A6%2064b4648229494c6b9075fede8dfeaa8c/Untitled.png](%E1%84%83%E1%85%AE%E1%84%87%E1%85%A5%E1%86%AB%E1%84%8D%E1%85%A2%20%E1%84%80%E1%85%AA%E1%84%8C%E1%85%A6%2064b4648229494c6b9075fede8dfeaa8c/Untitled.png)

```
a. 모델의 오차는 모든 Y 데이터에 대한 모든 오차값을 이용하여 계산한다.
b. 제곱을 하는 이유는 오차를 더할때 +, - 값이 서로 상쇄되지 않게 하기 위함이다.
c. 제곱을 하는 이유는 작은 오차보다, 큰 오차에 초점을 두기 위해서이다.
d. (위 수식 참고) 모델은 ŷ값이 Y에 수렴하도록 학습한다.
```

### 풀이)

---

답: **(a)**

(a) 모든 Y 데이터가 아닌 표본으로 뽑은 n개의 데이터에 대하여 오차값을 이용

(b) 제곱을 함으로써, 거리가 항상 양수로 나올 수 있어서 상쇄되지 않음

(c) 제곱을 함으로써, 오차가 큰 경우에 대하여 패널티를 더 부여하게 됨

(d) cost의 값을 줄이는 것이 목표이므로 맞음

### 기여자

강찬울, 김영재, 양가영, 이연경, 이현재: 스터디 시간에 다함께 의견 나누었다.

-

(a)에서 '모든 Y 데이터'가 전체 집합에 있는 모든 데이터를 의미하는 것인지

표본 안에 있는 모든 데이터를 의미하는 것인지 의견이 나뉘었고 전자의 뜻을 따르기로 결정하였다.

-

답이 (c)가 아니냐는 의견이 나왔고,

이를 검토하기 위해, '모두의 딥러닝 ML lec02'를 다시 들은 후,

양가영 님이 보내주신 아래 자료를 참고하여 (c)가 맞음을 최종 확인하였다

[선형회귀 MSE 오차함수 미분 및 코드 구현](http://taewan.kim/post/cost_function_derivation/)

### 검수자

이연경

---

# 문제 2.

### 문제 내용)

---

```
# 실습 문제 2 + 풀이
'''
모델을 수정하여 2개의 입력을 받으면 1개의 입력을 내는 모델을 만들어 구동하세요.

train만 학습으로 사용가능합니다
target을 넣었을 때 나온 값으로 평가합니다.

train
[0.1, 0.2] -> 0
[0.3, 0.4] -> 1
target
[0.5, 0.6] -> 2
평가기준
[0.5, 0.6] -> 1.9~2.1
통과예시
[1.9622281] (다른 값이 될 수도 있습니다.)
'''
```

**답안예시**

결과를 다음과 같이 캡처해서 제출하면 됩니다.

![%E1%84%83%E1%85%AE%E1%84%87%E1%85%A5%E1%86%AB%E1%84%8D%E1%85%A2%20%E1%84%80%E1%85%AA%E1%84%8C%E1%85%A6%2064b4648229494c6b9075fede8dfeaa8c/Untitled%201.png](%E1%84%83%E1%85%AE%E1%84%87%E1%85%A5%E1%86%AB%E1%84%8D%E1%85%A2%20%E1%84%80%E1%85%AA%E1%84%8C%E1%85%A6%2064b4648229494c6b9075fede8dfeaa8c/Untitled%201.png)

### 풀이)

---

```jsx
import numpy as np
import tensorflow as tf

x_train = np.array([[0.1, 0.2],[0.3, 0.4]]) # 채워넣어주세요
y_train = np.array([0,1]) # 채워넣어주세요

tf.model = tf.keras.Sequential()
tf.model.add(tf.keras.layers.Dense(units=1, input_dim=2)) # input_dim 수정하세요

sgd = tf.keras.optimizers.SGD(lr=0.1)
tf.model.compile(loss='mse', optimizer=sgd)

tf.model.summary()

tf.model.fit(x_train, y_train, epochs=1000, verbose=0) # epoch 수정해보면서 하세요

y_predict = tf.model.predict(np.array([[0.5, 0.6]]))
print(y_predict)
```

![%E1%84%83%E1%85%AE%E1%84%87%E1%85%A5%E1%86%AB%E1%84%8D%E1%85%A2%20%E1%84%80%E1%85%AA%E1%84%8C%E1%85%A6%2064b4648229494c6b9075fede8dfeaa8c/2.png](%E1%84%83%E1%85%AE%E1%84%87%E1%85%A5%E1%86%AB%E1%84%8D%E1%85%A2%20%E1%84%80%E1%85%AA%E1%84%8C%E1%85%A6%2064b4648229494c6b9075fede8dfeaa8c/2.png)

epochs : 총 훈련 횟수
input_dim : 입력 차원 수

### 기여자

강찬울, 김영재, 양가영, 이연경, 이현재: 코드를 공유하며 스터디 시간에 다함께 의견 나누었다.

### 검수자

이연경

---

# 문제 3.

### 문제 내용)

---

```
다음 중 틀린 것을 고르세요.

1.Unsupervised learning type으로는 linear regression, classfication이 있다.
2.주택가격,기온을 linear regression을 사용하여 예측할 수 있다.
3.주택가격을 예측하는 모델에서 하나의 집 (집과 판매가격)을 ’샘플’, 그리고 그 집의 판매가격을 ‘레이블(label)’이라고 한다.
4.AlphaGo는 supervised learing을 이용해서 만들었다.
```

### 풀이)

---

답: **(1)**

(1) Unsupervised learning이 아니라 Supervised learning에 대한 설명이다.

### 기여자

강찬울, 김영재, 양가영, 이연경, 이현재: 스터디 시간에 다함께 의견 나누었다.

이연경: (3)에서 샘플을 집과 판매가격으로만 잡아도 되는 것인지, 집 판매가격에 영향을 미치는 독립변수 (ex) 주택 근처 지역의 범죄율)에 대한  설명은 없어도 되는지 의심을 가졌지만, 이 문제에서는 구체적인 언급이 없기 때문에 필요하지 않은 생각이었다.

### 검수자

이연경

---

# 문제 4.

### 문제 내용)

---

경사하강법을 gradient_descent()라는 함수를 생성해서 구현해보도록 합시다.

gradient_descent()는 w1과 w0을 모두 0으로 초기한 뒤, iters개수만큼 반복하면서 w1과 w0을 업데이트합니다. 이를 위해 gradient_descent() 함수를 사용합니다. get_weight_updates() w1 과 w0 를 업데이트 할 w1_update, w0_update를 반환하는 함수 입니다.

### 풀이)

---

```jsx
# w1 과 w0 를 업데이트 할 w1_update, w0_update를 반환. 
def get_weight_updates(w1, w0, X, y, learning_rate=0.01):
    N = len(y)
    # 먼저 w1_update, w0_update를 각각 w1, w0의 shape와 동일한 크기를 가진 0 값으로 초기화
    w1_update = np.zeros_like(w1)
    w0_update = np.zeros_like(w0)
    # 예측 배열 계산하고 예측과 실제 값의 차이 계산
    y_pred = np.dot(X,w1.T) + w0
    diff = y-y_pred
         
    # w0_update를 dot 행렬 연산으로 구하기 위해 모두 1값을 가진 행렬 생성 
    w0_factors = np.ones((N,1))

    # w1과 w0을 업데이트할 w1_update와 w0_update 계산
    w1_update = -(2/N)*learning_rate*(np.dot(X.T, diff))
    w0_update = -(2/N)*learning_rate*(np.dot(w0_factors.T, diff))
    
    return w1_update, w0_update

#반복적으로 경사 하강법을 이용하여 get_weigth_updates()를 호출하여 w1과 w0를 업데이트 하는 함수 생성
def gradient_descent_steps(X, y, iters=10000):
    # w0와 w1을 모두 0으로 초기화. 
    w0 = np.zeros((1,1))
    w1 = np.zeros((1,1))
    
    # 인자로 주어진 iters 만큼 반복적으로 get_weight_updates() 호출하여 w1, w0 업데이트 수행. 
    for ind in range(iters):
        w1_update, w0_update = get_weight_updates(w1, w0, X, y, learning_rate=0.01)
        w1 = w1 - w1_update
        w0 = w0 - w0_update
              
    return w1, w0

def get_cost(y, y_pred):
    N = len(y) 
    cost = np.sum(np.square(y - y_pred))/N
    return cost

w1, w0 = gradient_descent_steps(X, y, iters=1000)
print("w1:{0:.3f} w0:{1:.3f}".format(w1[0,0], w0[0,0]))
y_pred = w1[0,0] * X + w0
print('Gradient Descent Total Cost:{0:.4f}'.format(get_cost(y, y_pred)))
```

### 기여자

강찬울, 김영재, 양가영, 이연경, 이현재: 코드를 비교하며 스터디 시간에 다함께 의견 나누었다.

양가영,이현재 : 인터넷에서 동일한 개념을 다룬 사이트를 찾아 공유하여 다른 팀원들의 이해를 도왔다.

[](https://velog.io/@sset2323/05-03.-%EB%B9%84%EC%9A%A9-%EC%B5%9C%EC%86%8C%ED%99%94%ED%95%98%EA%B8%B0-%EA%B2%BD%EC%82%AC-%ED%95%98%EA%B0%95%EB%B2%95Gradient-Descent-%EC%86%8C%EA%B0%9C)

### 검수자

이연경

---

# 문제 5.

### 문제 내용)

---

다음 데이터셋을 이용하여 값을 예측해보세요.  

```
다음 데이터셋을 이용하여 값을 예측해보세요.  

target 5,4 → -4,-3
평가기준 loss 0.001 이하
(1행은 X_train 2행은 Y_train
```

### 풀이)

---

```jsx
from google.colab import files
myfile = files.upload()

import io
import pandas as pd
import numpy as np
import tensorflow as tf
data = np.loadtxt(io.BytesIO(myfile['Book3.csv']))
print(data)

x_train = np.array(data[0])
y_train = np.array(data[1])
print(x_train, y_train)
tf.model = tf.keras.Sequential()
tf.model.add(tf.keras.layers.Dense(units=1, input_dim=1))

sgd = tf.keras.optimizers.SGD(lr=0.1)
tf.model.compile(loss='mse', optimizer=sgd)

tf.model.summary()

tf.model.fit(x_train, y_train, epochs=1000, verbose=0)

y_predict = tf.model.predict(np.array([5,4]))
print(y_predict)
```

### 기여자

강찬울, 김영재, 양가영, 이연경, 이현재: 코드를 비교하며 스터디 시간에 다함께 의견 나누었다.

-

강찬울,김영재,양가영,이연경:

pd.read_csv()를 이용하여  데이터를 불러올 경우, X_train과 Y_train을 어떻게 만들 수 있는지 어려움을 겪고 있었는데

이현재:

위와 같은 풀이방법을 제시해주었다.

### 검수자

이연경

---