# [첫번째 과제]

- ***1번****

답 : c

풀이

supervised learning은 training 셋을 토대로 학습을 하여 결과값을 예측하거나 분류하는 학습 방법이다.

Unsupervised learning은 주어진 환경에서 패턴을 파악하여 학습하는 방법이다.

a는 supervised learning의 training 셋에 대한 설명이고

b는 이미지 라벨링을 통한 supervised learning이고

d는 주어진 데이터를 이용해서 결과값을 예측하는 supervised learning이다.

c는 커뮤니티의 게시물들을 파악해서 grouping하는 unsupervised learning이다.

- ***기여자****

강찬울, 김영재, 양가영, 이연경, 이현재: 스터디 시간에 다함께 의견 나누었다.

- ***최종검수자****

이연경

- ***2번****

답 : a

풀이

a는 Scalar가 아닌 Matrix다.

Scalar의 표현은 a = 617로 나타낸다.

- ***기여자****

강찬울, 김영재, 양가영, 이연경, 이현재: 스터디 시간에 다함께 의견 나누었다.

강찬울: a가 왜 오답인지 깔끔한 풀이를 제시하였다.

- ***최종검수자****

이연경

- ***3번****

풀이 1 - tensorflow 쓰지 않은 경우

import numpy as np

import tensorflow as tf

x = np.array([1,2,3])

w = np.array([1.1])

y_hat = np.array([1,2,3])

def H(x):

return w * x

y = H(x)

cost = np.sum(np.square(y-y_hat))

print(f'y {y}')

print(f'cost {cost}')

풀이 2 - tensorflow 쓴 경우

import numpy as np

import tensorflow as tf

x = np.array([1,2,3])

w = np.array([1.1])

y_hat = np.array([1,2,3])

y = w * x

cost = tf.reduce_mean(tf.square(y-y_hat))

print("y",y)

tf.print("cost",cost)

- ***기여자****

강찬울, 김영재, 양가영, 이연경, 이현재

: 서로의 풀이법을 비교해보니

tensorflow를 쓴 경우와 쓰지 않는 경우, 각각의 풀이가 달라질 수 있는 것을 감안하여 2가지 풀이법을 제시하였다.

- ***최종검수자****

이연경

- ***4번****

import tensorflow as tf

assert tf.**__version__**.startswith('1')

a = tf.placeholder(dtype=tf.int32, shape=[])

b = tf.constant(3)

c = tf.Variable(5)

r_1 = a - b

r_2 = 2 * r_1

z = r_2 + c

sess = tf.Session()

sess.run(tf.global_variables_initializer())

print(sess.run(z, feed_dict={a:2}))

print(sess.run(z, feed_dict={a:7}))

print(sess.run(z, feed_dict={a:5}))

print(sess.run(z, feed_dict={a:10}))

print(sess.run(z, feed_dict={a:-5}))

- ***기여자****

강찬울, 김영재, 양가영, 이연경, 이현재 : 스터디 시간에 다함께 의견 나누었다.

이연경: 마지막 부분 코드를 feed_dict={a:2,b:3,c:5} 이렇게 잘못 짜온 것을

이현재: b,c라는 변수에 들어있는 숫자를 바로 이용하는 방법으로 바꾸자고 제안하였다.

https://bcho.tistory.com/1150를 참고하여

init = tf.global_variables_initializer()

sess.run(init)

다음과 같은 코드를 추가하면 해결할 수 있다는 것을 찾아내었다.

강찬울, 김영재, 양가영, 이연경, 이현재: 이후, 추가한 코드를 이해하며 문제를 풀었다.

- ***최종검수자****

이연경

- ***5번****

**numpy**

import numpy as np

\## Hypothesis 구현

y_pred = np.dot(W, X) + b

\## Cost 함수 구현

def get_cost(y, y_pred):

N = len(y)

cost = np.sum(np.square(y_pred - y)) / N

return cost

**tensorflow**

import tensorflow as tf

\## Hypothesis 구현

y_pred=tf.tensordot(W,X,1)+b

\## Cost 함수 구현

def get_cost(y,y_pred):
cost= tf.reduce_mean(tf.square(y_pred-y))
return cost

****기여자****

강찬울, 김영재, 양가영, 이연경, 이현재

:스터디 시간에 다함께 의견 나누었다.

:처음에 예측값이 왜 문제와 같이 나오는지 이해가 되지 않아 오랜시간 고민했다.

:문제 3번과 5번의 풀이법이 너무 유사하다 생각하여, 혹시 다른 출제 의도가 있는 것은 아닐까 생각했다.

김영재: 조원들이 문제에 대한 해석을 어려워하자 이를 출제자에게 직접 질문한 후 문제 의도를 조원들이 이해할 수 있도록 설명해주었다.

양가영: https://techblog-history-younghunjo1.tistory.com/121와 https://chacha95.github.io/2018-11-05-Regression/을 참고하여 X(1)~X(100),w1이 스칼라뿐만 아니라 벡터로 확장될 수도 있겠다는 아이디어를 제공하였다.

김영재: X(1)~X(100),w1이 스칼라이든 벡터이든 y_pred를 계산하기 위해 내적해야한다는 사실은 변함이 없다는 것을 찾아내었다 => np.dot 이용하자는 의견 제시

- ***최종검수자****

이연경