# 3주차

---

# 문제 1. 간단한 이론 문제

---

- 문제 1번

    ### 문제타입

    - [x]  이론
    - [ ]  실습

    ---

    ### 문제내용

    ```
    다음 중 Logistic Classification에 대한 설명으로 틀린 것을 고르시오.

    a. Logistic Classification으로 어린이대공원에 있는 동물들을 분류하는 문제를 풀 수 있다.
    b. 0~1사이에서 움직이는 새로운 hypothesis를 위해, 0을 기준으로 기울기가 급변하는 sigmoid 함수를 도입했다.  
    c. logistic hypothesis를 기존의 cost function에 사용하면 global minima의 개수가 많아 local minima을 찾기 어려워 예측값의 정확도가 낮아진다.
    d. cost funtion의 값은 예측에 성공했을 시 0에 가까워지고 실패했을 시 한없이 커진다.
    ```

    ---

    ### 출제 정보

    **출제자**

    이세희, 문예완, 박성열, 고규환 : 문제 출제 및 보기 출제

    **검수자**

    팀원모두

    **기타**

    출제일자 **:** 2021.05.04

---

- 풀이

    **정답 : C**

    c) local minima가 많아 global minima를 찾기 어려워짐

    ### 기여자

    팀원 모두 각자가 풀어온 것을 토대로 의견을 제시하였고 모두가 c를 정답으로 생각

    ### 검수자

    이연경

# 문제 2 : Pandas 이용하여 데이터 만지기

---

- 문제 2번

    ### 문제타입

    - [ ]  이론
    - [x]  실습

    ---

    ### 문제내용

    ![3%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%202319da5bcd0b4ba48a9e2e85cc9ca8bb/Untitled.png](3%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%202319da5bcd0b4ba48a9e2e85cc9ca8bb/Untitled.png)

    ```
    xy= np.loadtxt("~~~.csv', delimiter=',', dtype=np.float32)
    x_data = xy[:, 0:-1]
    y_data = xy[:, [-1]]

    이 코드는 강의 내용에 나온 코드의 일부로
    numpy를 이용해 데이터를 불러오고 원하는 부분을 x_data, y_data로 분류하는 부분이다.

    위의 코드를 pandas를 이용해 2가지 방법으로 변환하고 
    아래 문제에서 제시한 코드를 구현하시오
    ```

    **Base Code**

    ```python
    import pandas as pd

    df=pd.read_csv('dataset.csv')

    x_data =       # 2가지 방법으로 작성하세요
    x_data =
    y_data =       # 2가지 방법으로 작성하세요
    y_data = 

    # 위의 데이터 셋에 행과 열을 각각 추가해주세요 (행 먼저 추가하고 열 추가)
    # 행과 열의 이름은 순서대로 따라가시면됩니다
    # 열에 추가할 데이터를 정하기 귀찮으면 range를 와 len을 활용해보세요!
    # 이때 들어가는 데이터는 자유롭게 작성해주시면 됩니다.

    #######

    #행 열 추가하는 코드

    #######

    #######

    #행 열 제거하는 코드
    # 데이터를 확인해서 a,b,c,d컬럼의 값이 1인 행을 제거해주세요
    # 그리고 a열을 제거해주세요

    #######

    # 이제 수정하신 데이터프레임을 csv로 저장해서 올려주세요

    # pd.read~~

    ```

    ### 데이터

    [dataset.csv](3%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%202319da5bcd0b4ba48a9e2e85cc9ca8bb/dataset.csv)

    ### 캡쳐본 및 완성된 csv파일

    ---

    ### 출제 정보

    **출제의도**

    모델을 학습하고 예측하기 위해선 그에 알맞는 데이터셋과 데이터의 형태가 중요합니다. 데이터셋을 처리하는 몇 가지 방법을 알아봅시다.

    이 데이터를 다루는 가장 기본적인 방법은 pandas라이브러리를 사용하는것입니다

    그러므로 판다스의 기본기를 다져봅시다!

    pandas내에서도 같은 결과값을 내는 여러가지 방법들이 존재합니다.

    이를 몇가지 경험해보고 자신에게 가장 맞는 방법을 찾아보세요!

    위 문제뿐만 아니라 pandas를 구현해서 데이터를 처리하는 다양한 방법에 대해 학습해 보는 것도 좋은 공부가 되지 않을까요..?(예를들어 query를 이용해 원하는 행이나 열을 추출한다던가...) 

    **출제자**

    문예완 : 문제, 코드작성

    **검수자**

    나머지 팀원들

    **기타**

    출제일자 **:** 2021.05.04

---

- 풀이

    ```python
    import pandas as pd

    df=pd.read_csv('dataset.csv')
    df

    #sol1) df.iloc: 행 번호를 기준으로 행 데이터 읽기
    x_data = df.iloc[:,0:-1]    # 2가지 방법으로 작성하세요
    y_data = df.iloc[:,-1]    # 2가지 방법으로 작성하세요

    #sol2) df.loc: 인덱스 기준으로 행 데이터 읽기
    x_data = df.loc[:,['a','b','c']]    # 2가지 방법으로 작성하세요
    y_data = df.loc[:,'d']    # 2가지 방법으로 작성하세요

    # 위의 데이터 셋에 행과 열을 각각 추가해주세요 (행 먼저 추가하고 열 추가)
    # 행과 열의 이름은 순서대로 따라가시면됩니다
    # 열에 추가할 데이터를 정하기 귀찮으면 range를 와 len을 활용해보세요!
    # 이때 들어가는 데이터는 자유롭게 작성해주시면 됩니다.

    #######

    #행 열 추가하는 코드

    #######
    # 행 추가
    k = df.iloc[0]
    df_1 = df.append(k, ignore_index=True)
    # 열 추가
    df_1['e']=range(len(df_1))
    df_1

    #######

    #행 열 제거하는 코드
    # 데이터를 확인해서 a,b,c,d컬럼의 값이 1인 행을 제거해주세요
    # 그리고 a열을 제거해주세요

    #######
    df_1 = df_1.drop(index=3) 
    df_1 = df_1.drop('a',axis=1)

    df_1.to_csv('new_dataset.csv',index=False)

    # pd.read~~
    pd.read_csv('new_dataset.csv')
    ```

    ### 기여자

    팀원 모두 각자 코딩해온 것을 바탕으로 좀 더 쉽고 간단하고 직관적인 코딩을 찾아감

    이연경, 양가영, 강찬울 : 데이터 분리 시 행을 기준으로 (데이터셋에서 마지막 행의 값이 유독 값이 커서)

    이현재, 김영재 : 데이터 분리 시 열을 기준으로 (문제 예시에 따라서)

    - 문제 예시에 따라 열을 기준으로 분리

    ### 검수자

    이연경

    ### 참고한 자료

    [판다스(pandas) - 행단위 데이터 읽기 (loc, iloc)](https://devpouch.tistory.com/47)

# 문제 3. 간단한 이론 문제

---

- 문제 3번

    ### 문제타입

    - [x]  이론
    - [ ]  실습

    ---

    ### 문제내용

    ```
    3. 다음 중 Multivariable linear regression에 대한 설명으로 틀린 것을 **모두** 고르시오. (답 2개)

    a. 독립변수가 여러 개이며, 독립변수와 종속변수 간의 관계가 선형인 형태를 의미한다.
    b. Instance 수만큼 가중치 수가 필요하다.
    c. matrix를 이용하여 [a,b]*[c,d]=[e,f]로 표현할 때, a는 변수의 개수, b는 data sample의 개수이며 b=c, a=e, d=f 이다.
    (이때, X=[a,b], W=[c,d], H(x)=[e,f]이며 a,b,c,d,e는 모두 값이 아닌 크기를 의미한다.)
    d. 선형회귀보다 더 좁은 범위안에서 움직이게 되었고, 좀 더 정밀한 예측을 할 수 있게 되었다.
    ```

    ---

    ### 출제 정보

    **출제자**

    팀원모두

    **검수자**

    팀원모두

    **기타**

    출제일자 **:** 2021.05.04

---

- 풀이

    **정답 : B, C**

    ---

    (b) Instance 수가 아니라 독립변수의 수만큼 가중치 수가 필요하다.

    (c) a : data sample의 개수,  b : 변수의 개수

    ### 기여자

    팀원 모두 각자가 풀어온 것을 토대로 의견을 제시하였고 모두가 b와 c를 정답으로 생각

    ### 검수자

    이연경

# 문제 4 : multi-variable 과 Matrix, 실습

---

- 문제 4번

    ### 문제타입

    - [ ]  이론
    - [x]  실습

    ---

    ### 문제내용

    ```
    x_data :
    [49, 56, 59]
    [70, 54, 48]
    [52, 47, 42]
    [41, 44, 62]
    [65, 64, 68]

    y_data: [173][168][153][135][180]

    를 사용하고, Base code 코드를 적절히 수정하여 예측 값(아래 사진)과 비슷하게 구하시오.
    ```

    **Base Code**

    ```python
    import tensorflow._api.v2.compat.v1 as tf  # version_1

    tf.disable_v2_behavior()

    # Base code
    x_data =  # x_data수정
    y_data =  # y_data수정

    # placeholders for a tensor that will be always fed.
    X = tf.placeholder(tf.float32, shape=[1, 5]) # shape 수정
    Y = tf.placeholder(tf.float32, shape=[8, 5]) # shape 수정

    W = tf.Variable(tf.random_normal([3, 1]), name='weight')
    b = tf.Variable(tf.random_normal([1]), name='bias')

    # Hypothesis
    hypothesis = tf.matmul(X, W) + b

    # Simplified cost/loss function
    cost = tf.reduce_mean(tf.square(hypothesis - Y))

    # Minimize
    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01) # learning_rate 수정
    train = optimizer.minimize(cost)

    # Launch the graph in a session.
    sess = tf.Session()
    # Initializes global variables in the graph.
    sess.run(tf.global_variables_initializer())

    for step in range(2001):
        cost_val, hy_val, _ = sess.run(
            [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})
        if step % 10 == 0:
            print(step, "Cost: ", cost_val, "\nPrediction:\n", hy_val)
    ```

    ![3%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%202319da5bcd0b4ba48a9e2e85cc9ca8bb/Untitled%201.png](3%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%202319da5bcd0b4ba48a9e2e85cc9ca8bb/Untitled%201.png)

    ---

    ### 출제 정보

    **출제의도**

     multi-variable 과 Matrix를 이해하였는지 테스트하기 위해 출제하여 보았습니다.

    **출제자**

    안정현 : 문제, 코드작성

    **검수자**

    나머지 팀원들

    **기타**

    출제일자 **:** 2021.05.04

---

- 풀이

    ```python
    import tensorflow._api.v2.compat.v1 as tf
    tf.disable_v2_behavior()
    # Base code
    x_data = [[49, 56, 59],[70, 54, 48],[52, 47, 42],
              [41, 44, 62],[65, 64, 68]] # x_data수정
    y_data = [[173],[168],[153],[135],[180]] # y_data수정

    # placeholders for a tensor that will be always fed.
    X = tf.placeholder(tf.float32, shape=[None, 3]) # shape 수정
    Y = tf.placeholder(tf.float32, shape=[None, 1]) # shape 수정

    W = tf.Variable(tf.random_normal([3, 1]), name='weight')
    b = tf.Variable(tf.random_normal([1]), name='bias')

    # Hypothesis
    hypothesis = tf.matmul(X, W) + b

    # Simplified cost/loss function
    cost = tf.reduce_mean(tf.square(hypothesis - Y))

    # Minimize
    optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5) # learning_rate 수정
    train = optimizer.minimize(cost)

    # Launch the graph in a session.
    sess = tf.Session()
    # Initializes global variables in the graph.
    sess.run(tf.global_variables_initializer())

    for step in range(2001):
        cost_val, hy_val, _ = sess.run(
            [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})
        if step % 10 == 0:
            print(step, "Cost: ", cost_val, "\nPrediction:\n", hy_val)
    ```

    ### 기여자

    팀원 모두

    ### 검수자

    이연경

# 문제 5 : TensorFlow1.0으로 Logistic Regression Classifier 구현하기

---

- 문제 5번

    ### 문제타입

    - [ ]  이론
    - [x]  실습

    ---

    ### 문제내용

    ![3%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%202319da5bcd0b4ba48a9e2e85cc9ca8bb/Untitled%202.png](3%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%202319da5bcd0b4ba48a9e2e85cc9ca8bb/Untitled%202.png)

    ![3%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%202319da5bcd0b4ba48a9e2e85cc9ca8bb/Untitled%203.png](3%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%202319da5bcd0b4ba48a9e2e85cc9ca8bb/Untitled%203.png)

    ![3%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%202319da5bcd0b4ba48a9e2e85cc9ca8bb/Untitled%204.png](3%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%202319da5bcd0b4ba48a9e2e85cc9ca8bb/Untitled%204.png)

    ```
     위에 보이는 데이터는 617명의 코로나 의심 환자의 검사 결과를 나타낸 표이다. 
    A~G열은 코로나 의심 환자의 7가지 검사의 결과이고 H열은 코로나 확진 여부이다.
    H열의 값이 1이면 코로나 검사 결과 양성, 0이면 음성을 뜻한다. 

    2주차 5번 문제에서 배운 pandas와 numpy를 이용하여 데이터파일을 불러온 후 
    sigmoid를 이용한 가설을 세워 환자가 코로나인지 학습하여 예측하는 코드를 작성하여라.
     
    * 정확성을 계산(accuracy compuation)할 때 기준은 hypothesis가 0.5 초과이면 true,
    이외는 false로 계산한 후 계산 된 결과가 결과값과 같은지 확률을 계산하여라.

    결과값을 출력할 때는 실제로 학습된 결과로 다시 파일의 내용을 측정해보고 얼마나
    정확한지 표 아래 결과값처럼 Accurcy를 출력하라.
    ```

    **Base Code**

    ```python
    import pandas as pd
    import numpy as np
    import tensorflow.compat.v1 as tf
    tf.disable_v2_behavior()

    Data=pd.read_csv(                                       ) #데이터를 파일에서 가져옴 
    x = Data[       ] # x_data는 처음부터 마지막 컬럼 전까지 측정값
    y = Data[       ] # y_data는 마지막 컬럼, 결과값

    X = tf.placeholder(               ) #n개의 데이터가 *개의 측정값으로 구성 
    Y = tf.placeholder(               ) #n개의 하나의 결과치로 구성

    #가중치 계산하기
    W = tf.Variable(tf.random_uniform(
        shape=[    ], minval=-1.0, maxval=1.0, dtype=tf.float32)) 

    #sigmoid를 이용하여 가설 구하기
    hypothesis =          (tf.matmul(X, W)) 
    # sigmoid 함수를 사용하지 않고도 한 번 구해보세요~ 

    #cost 계산 																						
    cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))

    #cost를 줄이기 위해 학습
    train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)

    #Accuracy계산
    predicted = tf.cast(          , dtype=tf.float32) # 결과값이 0.5이상이면 1 아니면 0
    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))
    #계산한 결과가 결과값과 같은지 확률을 계산해요

    # 세션을 할당하고 초기화 해줍니다.
    with tf.Session() as sess: 
        sess.run(tf.global_variables_initializer())

        for step in range(10001):#루프값을 바꿔가며 정확도의 차이를 확인해보세요
            sess.run(train, feed_dict={          })
            if step % 200 == 0:#200번 돌때마다 step과 cost를 출력해보세요
                print(step, sess.run(cost, feed_dict={
                                }), sess.run(W))

       #실제로 학습된 결과로 다시 파일의 내용을 측정해보고 얼마나 정확한지 Accuracy를
       #출력해봐요
        h, c, a = sess.run([hypothesis, predicted, accuracy],
                           feed_dict={X: x, Y: y})
        print ("\nHypothesis: ", h, "\nCorrect (Y): ", c, "\nAccuracy: ", a)

    	#Accuracy값을 통해 몇퍼센트 확률로 코로나에 걸렸는지 아닌지를 판별 가능합니다.

    ```

    ### 데이터

    [Q3.csv](3%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%202319da5bcd0b4ba48a9e2e85cc9ca8bb/Q3.csv)

    ---

    ### 출제 정보

    **출제의도**

    직접 데이터 셋을 불러오고 데이터 셋을 이용하여 모두의 딥러닝 강좌에서 배운  Logistic Classification을 직접 구현해 보는 것이 이론으로만 배우고 넘어가는 것 보다 와 닿을 것 같아

    직접 데이터를 가공하여 출제하여 보았습니다. 

    실생활에 밀접히 스며들어 있는 코로나 바이러스를 이용하여 문제를 출제하여 조금 더 친밀한 느낌을 내기 위해 노력했는데 문제를 풀며 흥미를 느끼셨으면 좋겠네요. 

    **출제자**

    박진석 : 문제, 코드작성

    **검수자**

    나머지 팀원들

    **기타**

    출제일자 **:** 2021.05.04

---

- 풀이

    ```python
    import pandas as pd
    import numpy as np
    import tensorflow.compat.v1 as tf
    tf.disable_v2_behavior()
    Data=pd.read_csv('Q3.csv') #데이터를 파일에서 가져옴
    x = Data.iloc[:,0:-1] # x_data는 처음부터 마지막 컬럼 전까지 측정값
    y = Data.iloc[:,[-1]] # y_data는 마지막 컬럼, 결과값

    X = tf.placeholder(tf.float32, shape=[None, 7]) #n개의 데이터가 *개의 측정값으로 구성 
    Y = tf.placeholder(tf.float32, shape=[None, 1]) #n개의 하나의 결과치로 구성

    #가중치 계산하기
    W = tf.Variable(tf.random_uniform(
        shape=[7,1], minval=-1.0, maxval=1.0, dtype=tf.float32)) 

    #sigmoid를 이용하여 가설 구하기
    hypothesis =tf.sigmoid(tf.matmul(X, W)) 
    # sigmoid 함수를 사용하지 않고도 한 번 구해보세요~ 
    # => hypothesis = tf.div(1.,1.+tf.exp(tf.matmul(X,W)))

    #cost 계산 																						
    cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))

    #cost를 줄이기 위해 학습
    train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)

    #Accuracy계산
    predicted = tf.cast(hypothesis >= 0.5, dtype=tf.float32) # 결과값이 0.5이상이면 1 아니면 0
    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))
    #계산한 결과가 결과값과 같은지 확률을 계산해요

    # 세션을 할당하고 초기화 해줍니다.
    with tf.Session() as sess: 
        sess.run(tf.global_variables_initializer())

        for step in range(10001):#루프값을 바꿔가며 정확도의 차이를 확인해보세요
            sess.run(train, feed_dict={X:x, Y:y})
            if step % 200 == 0:#200번 돌때마다 step과 cost를 출력해보세요
                print(step, sess.run(cost, feed_dict={X:x, Y:y}), sess.run(W))

       #실제로 학습된 결과로 다시 파일의 내용을 측정해보고 얼마나 정확한지 Accuracy를
       #출력해봐요
        h, c, a = sess.run([hypothesis, predicted, accuracy],
                           feed_dict={X: x, Y: y})
        print ("\nHypothesis: ", h, "\nCorrect (Y): ", c, "\nAccuracy: ", a)

    	#Accuracy값을 통해 몇퍼센트 확률로 코로나에 걸렸는지 아닌지를 판별 가능합니다.
    ```

    ### 기여자

    x,y를 가져오는 과정에서 의견이 나뉘었으나 서로 의견을 나눈 뒤 결과에 도달

    나머지 부분은 다들 어렵지 않게 해옴

    ### 검수자

    이연경